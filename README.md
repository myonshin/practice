{::options parse_block_html="true" /}

### Seokil Kang

I am a Ph.D. candidates in Economics at Indiana University, Bloomington. I expect to graduate in May 2022 and will be available for interviews at the 2022 ASSA virtual meeting.

Email: sk86@iu.edu

Field of Interest: Macroeconomics, Monetary and fiscal policy, Bayeseian Econometrics

### [Curriculum Vitae (PDF)](CV_Kang.pdf)

<br>

### Working Papers
<details>
  <summary markdown="span"><font color="blue">Quantifying the Fiscal Backing for Monetary Policy (Job Market Paper, Draft coming soon)</font> 
    
  <font color="black"> <b><i></i></b></font></summary>
  
  
  | **Abstract**          |
  |:---------------------------|
  | Successful inflation targeting requires fiscal policy to adjust the primary surplus path to meet the changes in the market value of government debt due to monetary policy shocks. In this paper, I estimate the response of primary surpluses to a monetary policy shock and examine whether such a response is present in data, as suggested by the theory of monetary-fiscal policy interaction. The U.S. data estimates capture the primary surpluses response, but with some shortage compared to what the theory prescribes. This result indicates that while the U.S. monetary policy has pinned down the price level, there is room for improvement with sufficient fiscal backing. I document that the necessity of primary surplus response to monetary policy shocks results from the dominant discount rate effect from the empirical perspective.
  
 </details>

 <br> 
 
 <details>
  <summary markdown="span"><font color="blue">Simulated Annealing Multiplicative Weights Algorithm for Solving a DSGE Model(Draft coming soon)</font>
    
  <font color="black"><b><i></i></b></font></summary>
    
  | **Abstract**          |
  |:---------------------------|
  | This paper introduces a simulation-based adaptive algorithm to solve a DSGE model with a large state space, namely the curse of dimensionality. It aims to generate a stationary distribution over policy space which is concentrated on the optimal policy. The key strategy is to construct a finite policy space of heuristic policies. To update the distribution over policy space, the method adopts on-line computation via iterative simulation with emphasis on rolling-horizon control to foster the speed of algorithm. Subsequently, I deliver that the algorithm achieves theoretical convergence to the optimal value function and the stationary distribution over policy space is concentrated on the optimal policy. Application to solve the simple two-period RBC model follows as a sample exercise. The result shows the performance is desirable within the feasible number of iterations and size of restricted policy space respectively.
  
 </details>

<br>

### Teaching
 
